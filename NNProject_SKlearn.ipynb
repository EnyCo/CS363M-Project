{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d444dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raghav Kalyanaraman, Chesca Untalan, Enay Bhatnagar\n",
    "\n",
    "# New Approach to Cleaning and feature Engineering for the Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccf4866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f86d75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome Type\n",
      "Adoption           0.495191\n",
      "Transfer           0.315086\n",
      "Return to Owner    0.149329\n",
      "Euthanasia         0.031028\n",
      "Died               0.009365\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load CSV\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# Drop the unnecessary columns: 'Id', 'Name', 'Found Location', 'Outcome Time', 'Date of Birth'\n",
    "df = df.drop(columns=['Id', 'Name', 'Found Location', 'Outcome Time', 'Date of Birth'], axis=1)\n",
    "\n",
    "print(df['Outcome Type'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbad9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHotEncodeList = []\n",
    "\n",
    "# Intake Time: \n",
    "\n",
    "# Check for missing values in the 'Intake Time' column\n",
    "# print(df['Intake Time'].isnull().sum()) => 0 missing vals\n",
    "\n",
    "# Convert 'Intake Time' to hour, day of the week, and month columns to be transformed\n",
    "df['hour'] = pd.to_datetime(df['Intake Time']).dt.hour\n",
    "df['dayofweek'] = pd.to_datetime(df['Intake Time']).dt.dayofweek\n",
    "df['month'] = pd.to_datetime(df['Intake Time']).dt.month\n",
    "\n",
    "\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "\n",
    "df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
    "df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
    "\n",
    "df['month_sin'] = np.sin(2 * np.pi * (df['month'] - 1) / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * (df['month'] - 1) / 12)\n",
    "\n",
    "# Drop the original 'Intake Time', 'hour', 'dayofweek', and 'month' columns\n",
    "df = df.drop(columns=['Intake Time', 'hour', 'dayofweek', 'month'], axis=1)\n",
    "\n",
    "# Intake Type: \n",
    "# Check for missing values in the 'Intake Type' column\n",
    "# print(df['Intake Type'].isnull().sum()) # => 0 missing vals\n",
    "\n",
    "# Delete the 'Wildlife' records (if any) from the 'Intake Type' column\n",
    "df = df[df['Intake Type'] != 'Wildlife']\n",
    "oneHotEncodeList.append('Intake Type')\n",
    "\n",
    "# Intake Condition:\n",
    "\n",
    "def group_intake_condition(condition):\n",
    "    if pd.isnull(condition):\n",
    "        return 'Other'\n",
    "    condition = condition.lower()\n",
    "    if condition in ['med attn', 'medical', 'med urgent', 'neurologic', 'congenital', 'parvo', 'agonal']:\n",
    "        return 'Medical-related'\n",
    "    elif condition in ['neonatal', 'aged', 'pregnant', 'nursing']:\n",
    "        return 'Life stage'\n",
    "    elif condition in ['normal', 'injured', 'sick']:\n",
    "        return 'Health Status'\n",
    "    elif condition in ['behavior', 'feral']:\n",
    "        return 'Behavioral'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "df['Intake Condition'] = df['Intake Condition'].apply(group_intake_condition)\n",
    "\n",
    "oneHotEncodeList.append('Intake Condition')\n",
    "\n",
    "# Animal Type:\n",
    "oneHotEncodeList.append('Animal Type')\n",
    "\n",
    "# Sex upon Intake: Split into two features => Sex and Neutered/Spayed\n",
    "\n",
    "# Check for missing values\n",
    "df['Sex upon Intake'] = df['Sex upon Intake'].fillna('Unknown')\n",
    "# print(df['Sex upon Intake'].isnull().sum())\n",
    "\n",
    "\n",
    "def extract_sex_and_status(sex):\n",
    "    if pd.isnull(sex): return pd.Series([\"Unknown\", \"Unknown\"])\n",
    "    \n",
    "    sex = sex.strip().lower()\n",
    "    if \"neutered\" in sex:\n",
    "        status = \"Neutered\"\n",
    "    elif \"spayed\" in sex:\n",
    "        status = \"Spayed\"\n",
    "    elif \"intact\" in sex:\n",
    "        status = \"Intact\"\n",
    "    else:\n",
    "        status = \"Unknown\"\n",
    "\n",
    "    if \"male\" in sex:\n",
    "        gender = \"Male\"\n",
    "    elif \"female\" in sex:\n",
    "        gender = \"Female\"\n",
    "    else:\n",
    "        gender = \"Unknown\"\n",
    "\n",
    "    return pd.Series([gender, status])\n",
    "\n",
    "df[['Sex', 'Fixed_Status']] = df['Sex upon Intake'].apply(extract_sex_and_status)\n",
    "\n",
    "\n",
    "oneHotEncodeList.append('Sex')\n",
    "oneHotEncodeList.append('Fixed_Status')\n",
    "\n",
    "# Drop original Sex upon Intake\n",
    "df = df.drop('Sex upon Intake', axis=1)\n",
    "\n",
    "\n",
    "# Age upon Intake: Convert to numeric values (in days) and drop the original column\n",
    "\n",
    "# print(df['Age upon Intake'].isnull().sum()) # => 0 missing vals\n",
    "def convert_age_to_days(age_str):\n",
    "    if pd.isnull(age_str):\n",
    "        return np.nan\n",
    "    num, unit = age_str.split()[:2]\n",
    "    num = int(num)\n",
    "    if 'day' in unit:\n",
    "        return num\n",
    "    elif 'week' in unit:\n",
    "        return num * 7\n",
    "    elif 'month' in unit:\n",
    "        return num * 30\n",
    "    elif 'year' in unit:\n",
    "        return num * 365\n",
    "    return np.nan\n",
    "\n",
    "df['Age upon Intake'] = df['Age upon Intake'].apply(convert_age_to_days)\n",
    "df['Age upon Intake'] = df['Age upon Intake'].fillna(df['Age upon Intake'].median())\n",
    "\n",
    "# print(df['Age upon Intake'].isnull().sum()) # => 0 missing vals\n",
    "\n",
    "# Breed:\n",
    "\n",
    "def process_breed(breed):\n",
    "    if pd.isnull(breed):\n",
    "        return pd.Series([\"Unknown\", True]) \n",
    "    \n",
    "    is_mix = \"Mix\" in breed or \"/\" in breed\n",
    "\n",
    "    if \"/\" in breed:\n",
    "        primary = breed.split(\"/\")[0].strip()\n",
    "    else:\n",
    "        primary = breed.replace(\" Mix\", \"\").strip()\n",
    "    return pd.Series([primary, is_mix])\n",
    "\n",
    "df[['Primary_Breed', 'Is_Mix']] = df['Breed'].apply(process_breed)\n",
    "\n",
    "df['Is_Mix'] = df['Is_Mix'].astype(int)\n",
    "\n",
    "vc = df['Primary_Breed'].value_counts()\n",
    "cumulative = vc.cumsum() / vc.sum()\n",
    "top_breeds = cumulative[cumulative <= 0.90].index\n",
    "df['Primary_Breed'] = df['Primary_Breed'].apply(lambda x: x if x in top_breeds else 'Other')\n",
    "\n",
    "# Drop the original 'Breed' column\n",
    "df = df.drop(columns=['Breed'], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "987a2c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "\n",
    "# Color: We have 3 potential features to extract from the color column\n",
    "# Base Colors (e.g., black, white, brown)\n",
    "# Patterns (e.g., tabby, brindle, tortie, merle)\n",
    "# Number of colors (solid vs. multi-colored)\n",
    "\n",
    "# color_counter = Counter()\n",
    "# pattern_counter = Counter()\n",
    "# for val in df['Color'].dropna():\n",
    "#     parts = re.split(r'[/ ]+', val)  # splits on '/' and spaces\n",
    "#     for part in parts:\n",
    "#         part_clean = part.strip().title()\n",
    "#         if part_clean: \n",
    "#             color_counter[part_clean] += 1\n",
    "\n",
    "\n",
    "base_colors = [\n",
    "    'White', 'Black', 'Brown', 'Tan', 'Blue', 'Orange', 'Red', 'Cream', 'Gray',\n",
    "    'Chocolate', 'Yellow', 'Fawn', 'Buff', 'Silver', 'Gold', 'Seal', 'Flame',\n",
    "    'Lilac', 'Apricot', 'Liver', 'Pink', 'Ruddy'\n",
    "]\n",
    "\n",
    "patterns = [\n",
    "    'Tabby', 'Brindle', 'Tricolor', 'Tortie', 'Calico', 'Point',\n",
    "    'Torbie', 'Merle', 'Sable', 'Lynx', 'Tick', 'Smoke', 'Tiger', 'Agouti'\n",
    "]\n",
    "\n",
    "color_groups = {\n",
    "    'Dark': ['Black', 'Chocolate', 'Seal'],\n",
    "    'Light': ['White', 'Cream', 'Buff', 'Silver'],\n",
    "    'Warm': ['Red', 'Orange', 'Flame', 'Gold', 'Apricot'],\n",
    "    'Cool': ['Blue', 'Gray', 'Lilac'],\n",
    "    'Neutral': ['Tan', 'Brown', 'Fawn', 'Yellow', 'Liver', 'Pink', 'Ruddy']\n",
    "}\n",
    "\n",
    "pattern_groups = {\n",
    "    'Striped': ['Tabby', 'Tiger', 'Lynx'],\n",
    "    'Blotched': ['Tortie', 'Calico', 'Torbie'],\n",
    "    'Gradient': ['Smoke', 'Point', 'Sable'],\n",
    "    'Mixed': ['Merle', 'Brindle', 'Tricolor'],\n",
    "    'Textured': ['Tick', 'Agouti'],\n",
    "    'None': []\n",
    "}\n",
    "\n",
    "\n",
    "color_to_group = {c: g for g, clist in color_groups.items() for c in clist}\n",
    "pattern_to_group = {p: g for g, plist in pattern_groups.items() for p in plist}\n",
    "\n",
    "# Group assignment functions\n",
    "def assign_color_group(color_str):\n",
    "    if pd.isnull(color_str): return \"Unknown\"\n",
    "    for part in re.split(r'[/ ]+', color_str):\n",
    "        name = part.strip().title()\n",
    "        if name in color_to_group:\n",
    "            return color_to_group[name]\n",
    "    return \"Other\"\n",
    "\n",
    "def assign_pattern_group(color_str):\n",
    "    if pd.isnull(color_str): return \"None\"\n",
    "    for part in re.split(r'[/ ]+', color_str):\n",
    "        name = part.strip().title()\n",
    "        if name in pattern_to_group:\n",
    "            return pattern_to_group[name]\n",
    "    return \"None\"\n",
    "\n",
    "# Apply to DataFrame\n",
    "df['Color_Group'] = df['Color'].apply(assign_color_group)\n",
    "df['Pattern_Group'] = df['Color'].apply(assign_pattern_group)\n",
    "\n",
    "# Drop the original 'Color' column\n",
    "df = df.drop(columns=['Color'], axis=1)\n",
    "\n",
    "oneHotEncodeList.append('Color_Group')\n",
    "oneHotEncodeList.append('Pattern_Group')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f084edcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age upon Intake     Outcome Type      hour_sin      hour_cos  \\\n",
      "0           2920.0  Return to Owner  1.224647e-16 -1.000000e+00   \n",
      "1            330.0  Return to Owner -1.000000e+00 -1.836970e-16   \n",
      "2            730.0         Transfer  0.000000e+00  1.000000e+00   \n",
      "3            730.0  Return to Owner  1.224647e-16 -1.000000e+00   \n",
      "4           2190.0  Return to Owner  7.071068e-01 -7.071068e-01   \n",
      "\n",
      "   dayofweek_sin  dayofweek_cos     month_sin     month_cos  \\\n",
      "0      -0.781831       0.623490  1.224647e-16 -1.000000e+00   \n",
      "1       0.433884      -0.900969  1.000000e+00  6.123234e-17   \n",
      "2       0.433884      -0.900969  8.660254e-01 -5.000000e-01   \n",
      "3      -0.974928      -0.222521  5.000000e-01  8.660254e-01   \n",
      "4       0.781831       0.623490  1.000000e+00  6.123234e-17   \n",
      "\n",
      "        Primary_Breed  Is_Mix  ...  Color_Group_Dark  Color_Group_Light  \\\n",
      "0               Other       0  ...             False               True   \n",
      "1               Other       1  ...             False               True   \n",
      "2  Domestic Shorthair       0  ...             False              False   \n",
      "3  Labrador Retriever       1  ...              True              False   \n",
      "4               Other       1  ...              True              False   \n",
      "\n",
      "   Color_Group_Neutral  Color_Group_Other  Color_Group_Warm  \\\n",
      "0                False              False             False   \n",
      "1                False              False             False   \n",
      "2                False              False              True   \n",
      "3                False              False             False   \n",
      "4                False              False             False   \n",
      "\n",
      "   Pattern_Group_Gradient  Pattern_Group_Mixed  Pattern_Group_None  \\\n",
      "0                   False                False                True   \n",
      "1                    True                False               False   \n",
      "2                   False                False               False   \n",
      "3                   False                False                True   \n",
      "4                   False                False                True   \n",
      "\n",
      "   Pattern_Group_Striped  Pattern_Group_Textured  \n",
      "0                  False                   False  \n",
      "1                  False                   False  \n",
      "2                   True                   False  \n",
      "3                  False                   False  \n",
      "4                  False                   False  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 111156 entries, 0 to 111156\n",
      "Data columns (total 33 columns):\n",
      " #   Column                            Non-Null Count   Dtype  \n",
      "---  ------                            --------------   -----  \n",
      " 0   Age upon Intake                   111156 non-null  float64\n",
      " 1   Outcome Type                      111156 non-null  object \n",
      " 2   hour_sin                          111156 non-null  float64\n",
      " 3   hour_cos                          111156 non-null  float64\n",
      " 4   dayofweek_sin                     111156 non-null  float64\n",
      " 5   dayofweek_cos                     111156 non-null  float64\n",
      " 6   month_sin                         111156 non-null  float64\n",
      " 7   month_cos                         111156 non-null  float64\n",
      " 8   Primary_Breed                     111156 non-null  object \n",
      " 9   Is_Mix                            111156 non-null  int64  \n",
      " 10  Intake Type_Euthanasia Request    111156 non-null  bool   \n",
      " 11  Intake Type_Owner Surrender       111156 non-null  bool   \n",
      " 12  Intake Type_Public Assist         111156 non-null  bool   \n",
      " 13  Intake Type_Stray                 111156 non-null  bool   \n",
      " 14  Intake Condition_Health Status    111156 non-null  bool   \n",
      " 15  Intake Condition_Life stage       111156 non-null  bool   \n",
      " 16  Intake Condition_Medical-related  111156 non-null  bool   \n",
      " 17  Intake Condition_Other            111156 non-null  bool   \n",
      " 18  Animal Type_Dog                   111156 non-null  bool   \n",
      " 19  Sex_Unknown                       111156 non-null  bool   \n",
      " 20  Fixed_Status_Neutered             111156 non-null  bool   \n",
      " 21  Fixed_Status_Spayed               111156 non-null  bool   \n",
      " 22  Fixed_Status_Unknown              111156 non-null  bool   \n",
      " 23  Color_Group_Dark                  111156 non-null  bool   \n",
      " 24  Color_Group_Light                 111156 non-null  bool   \n",
      " 25  Color_Group_Neutral               111156 non-null  bool   \n",
      " 26  Color_Group_Other                 111156 non-null  bool   \n",
      " 27  Color_Group_Warm                  111156 non-null  bool   \n",
      " 28  Pattern_Group_Gradient            111156 non-null  bool   \n",
      " 29  Pattern_Group_Mixed               111156 non-null  bool   \n",
      " 30  Pattern_Group_None                111156 non-null  bool   \n",
      " 31  Pattern_Group_Striped             111156 non-null  bool   \n",
      " 32  Pattern_Group_Textured            111156 non-null  bool   \n",
      "dtypes: bool(23), float64(7), int64(1), object(2)\n",
      "memory usage: 11.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Review the DataFrame after processing\n",
    "# print(df.head())\n",
    "# print(df.info())\n",
    "\n",
    "# One-hot encoding for categorical variables\n",
    "# print(oneHotEncodeList)\n",
    "df = pd.get_dummies(df, columns=oneHotEncodeList, drop_first=True)\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ee452de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode the 'Primary_Breed' column\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['Primary_Breed'] = le.fit_transform(df['Primary_Breed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1e21077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features shape: (111156, 32)\n",
      "Reduced features shape: (111156, 24)\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Adoption       0.63      0.78      0.70     55044\n",
      "           Died       0.16      0.04      0.07      1041\n",
      "     Euthanasia       0.32      0.07      0.11      3449\n",
      "Return to Owner       0.55      0.53      0.54     16598\n",
      "       Transfer       0.60      0.45      0.51     35024\n",
      "\n",
      "       accuracy                           0.61    111156\n",
      "      macro avg       0.45      0.37      0.39    111156\n",
      "   weighted avg       0.60      0.61      0.59    111156\n",
      "\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best Parameter: {'n_estimators': 300}\n",
      "Best Accuracy: 0.6112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split the data into features and labels\n",
    "features = df.drop(columns=['Outcome Type'])\n",
    "labels = df['Outcome Type']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "# Use PCA to reduce dimensionality\n",
    "print(f\"Original features shape: {features.shape}\")\n",
    "\n",
    "pca = PCA(n_components=0.95)  # Keep 95% of variance\n",
    "features = pca.fit_transform(features)\n",
    "print(f\"Reduced features shape: {features.shape}\")\n",
    "\n",
    "randomForest = RandomForestClassifier(random_state=10)\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 250, 300],\n",
    "}\n",
    "\n",
    "gs_rf = GridSearchCV(randomForest, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "predictions = cross_val_predict(gs_rf, features, labels, cv=5)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(labels, predictions))\n",
    "\n",
    "gs_rf.fit(features, labels)\n",
    "\n",
    "print(f\"Best Parameter: {gs_rf.best_params_}\")\n",
    "print(f\"Best Accuracy: {gs_rf.best_score_:.4f}\")\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# mlp = MLPClassifier()\n",
    "# pipeline = Pipeline(steps=[('scaler', scaler),('mlp', mlp)])\n",
    "\n",
    "# param_grid = {\n",
    "#     'mlp__hidden_layer_sizes': [(30,), (40,), (50,), (60,)],\n",
    "#     'mlp__activation': ['logistic', 'tanh', 'relu']\n",
    "# }\n",
    "# gs_mlp = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "# accuracy = cross_val_score(gs_mlp, features, labels, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# print(f\"Accuracy of the neural net: {np.mean(accuracy):.4f} ± {np.std(accuracy):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2fe03cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Adoption       0.97      0.99      0.98     55044\n",
      "           Died       0.98      0.79      0.87      1041\n",
      "     Euthanasia       0.99      0.92      0.96      3449\n",
      "Return to Owner       0.99      0.99      0.99     16598\n",
      "       Transfer       0.97      0.96      0.97     35024\n",
      "\n",
      "       accuracy                           0.97    111156\n",
      "      macro avg       0.98      0.93      0.95    111156\n",
      "   weighted avg       0.97      0.97      0.97    111156\n",
      "\n",
      "Final Accuracy: 0.9748461621504912\n",
      "Confusion Matrix:\n",
      "[[54265     5    10    64   700]\n",
      " [  129   820     4     4    84]\n",
      " [  142     4  3188     8   107]\n",
      " [  170     0     4 16352    72]\n",
      " [ 1226    11    12    40 33735]]\n",
      "Balanced Accuracy Score: 0.9292506620119221\n"
     ]
    }
   ],
   "source": [
    "# Given best parameters, try the model on the entire dataset\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, balanced_accuracy_score\n",
    "\n",
    "best_rf = RandomForestClassifier(**gs_rf.best_params_, random_state=10)\n",
    "best_rf.fit(features, labels)\n",
    "predictions = best_rf.predict(features)\n",
    "\n",
    "print(\"Final Classification Report:\")\n",
    "print(classification_report(labels, predictions))\n",
    "print(\"Final Accuracy:\", accuracy_score(labels, predictions))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(labels, predictions))\n",
    "print(\"Balanced Accuracy Score:\", balanced_accuracy_score(labels, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570fa5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raghav\\AppData\\Local\\Temp\\ipykernel_12600\\3548398757.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  test_df['hour'] = pd.to_datetime(test_df['Intake Time']).dt.hour\n",
      "C:\\Users\\Raghav\\AppData\\Local\\Temp\\ipykernel_12600\\3548398757.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  test_df['dayofweek'] = pd.to_datetime(test_df['Intake Time']).dt.dayofweek\n",
      "C:\\Users\\Raghav\\AppData\\Local\\Temp\\ipykernel_12600\\3548398757.py:18: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  test_df['month'] = pd.to_datetime(test_df['Intake Time']).dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features shape: (27791, 32)\n",
      "Reduced features shape: (27791, 24)\n",
      "Length of predictions: 27791\n",
      "Submission file saved as submission.csv\n"
     ]
    }
   ],
   "source": [
    "test_df = None\n",
    "test_data = pd.read_csv('test.csv')\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "# Drop the unnecessary columns: 'Id', 'Name', 'Found Location', 'Outcome Time', 'Date of Birth'\n",
    "test_df = test_df.drop(columns=['Id', 'Found Location', 'Date of Birth'], axis=1)\n",
    "\n",
    "oneHotEncodeList = []\n",
    "\n",
    "# Intake Time: \n",
    "\n",
    "# Check for missing values in the 'Intake Time' column\n",
    "# print(test_df['Intake Time'].isnull().sum()) => 0 missing vals\n",
    "\n",
    "# Convert 'Intake Time' to hour, day of the week, and month columns to be transformed\n",
    "\n",
    "test_df['hour'] = pd.to_datetime(test_df['Intake Time']).dt.hour\n",
    "test_df['dayofweek'] = pd.to_datetime(test_df['Intake Time']).dt.dayofweek\n",
    "test_df['month'] = pd.to_datetime(test_df['Intake Time']).dt.month\n",
    "\n",
    "#Doing sin and cos transformations for hour, dayofweek, and month\n",
    "# Enables the model to learn cyclical patterns in the data\n",
    "# i.e hour 23 and hour 0 are close to each other in time, but numerically they are far apart.\n",
    "\n",
    "test_df['hour_sin'] = np.sin(2 * np.pi * test_df['hour'] / 24)\n",
    "test_df['hour_cos'] = np.cos(2 * np.pi * test_df['hour'] / 24)\n",
    "\n",
    "test_df['dayofweek_sin'] = np.sin(2 * np.pi * test_df['dayofweek'] / 7)\n",
    "test_df['dayofweek_cos'] = np.cos(2 * np.pi * test_df['dayofweek'] / 7)\n",
    "\n",
    "test_df['month_sin'] = np.sin(2 * np.pi * (test_df['month'] - 1) / 12)\n",
    "test_df['month_cos'] = np.cos(2 * np.pi * (test_df['month'] - 1) / 12)\n",
    "\n",
    "# Drop the original 'Intake Time', 'hour', 'dayofweek', and 'month' columns\n",
    "test_df = test_df.drop(columns=['Intake Time', 'hour', 'dayofweek', 'month'], axis=1)\n",
    "\n",
    "# Intake Type: \n",
    "# Check for missing values in the 'Intake Type' column\n",
    "# print(test_df['Intake Type'].isnull().sum()) # => 0 missing vals\n",
    "\n",
    "# Delete the 'Wildlife' records (if any) from the 'Intake Type' column\n",
    "test_df = test_df[test_df['Intake Type'] != 'Wildlife']\n",
    "oneHotEncodeList.append('Intake Type')\n",
    "\n",
    "# Intake Condition:\n",
    "\n",
    "def group_intake_condition(condition):\n",
    "    if pd.isnull(condition):\n",
    "        return 'Other'\n",
    "    condition = condition.lower()\n",
    "    if condition in ['med attn', 'medical', 'med urgent', 'neurologic', 'congenital', 'parvo', 'agonal']:\n",
    "        return 'Medical-related'\n",
    "    elif condition in ['neonatal', 'aged', 'pregnant', 'nursing']:\n",
    "        return 'Life stage'\n",
    "    elif condition in ['normal', 'injured', 'sick']:\n",
    "        return 'Health Status'\n",
    "    elif condition in ['behavior', 'feral']:\n",
    "        return 'Behavioral'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "test_df['Intake Condition'] = test_df['Intake Condition'].apply(group_intake_condition)\n",
    "\n",
    "oneHotEncodeList.append('Intake Condition')\n",
    "\n",
    "# Animal Type:\n",
    "oneHotEncodeList.append('Animal Type')\n",
    "\n",
    "# Sex upon Intake: Split into two features => Sex and Neutered/Spayed\n",
    "\n",
    "# Check for missing values\n",
    "test_df['Sex upon Intake'] = test_df['Sex upon Intake'].fillna('Unknown')\n",
    "# print(test_df['Sex upon Intake'].isnull().sum())\n",
    "\n",
    "\n",
    "def extract_sex_and_status(sex):\n",
    "    if pd.isnull(sex): return pd.Series([\"Unknown\", \"Unknown\"])\n",
    "    \n",
    "    sex = sex.strip().lower()\n",
    "    if \"neutered\" in sex:\n",
    "        status = \"Neutered\"\n",
    "    elif \"spayed\" in sex:\n",
    "        status = \"Spayed\"\n",
    "    elif \"intact\" in sex:\n",
    "        status = \"Intact\"\n",
    "    else:\n",
    "        status = \"Unknown\"\n",
    "\n",
    "    if \"male\" in sex:\n",
    "        gender = \"Male\"\n",
    "    elif \"female\" in sex:\n",
    "        gender = \"Female\"\n",
    "    else:\n",
    "        gender = \"Unknown\"\n",
    "\n",
    "    return pd.Series([gender, status])\n",
    "\n",
    "test_df[['Sex', 'Fixed_Status']] = test_df['Sex upon Intake'].apply(extract_sex_and_status)\n",
    "\n",
    "\n",
    "oneHotEncodeList.append('Sex')\n",
    "oneHotEncodeList.append('Fixed_Status')\n",
    "\n",
    "# Drop original Sex upon Intake\n",
    "test_df = test_df.drop('Sex upon Intake', axis=1)\n",
    "\n",
    "\n",
    "# Age upon Intake: Convert to numeric values (in days) and drop the original column\n",
    "\n",
    "# print(test_df['Age upon Intake'].isnull().sum()) # => 0 missing vals\n",
    "def convert_age_to_days(age_str):\n",
    "    if pd.isnull(age_str):\n",
    "        return np.nan\n",
    "    num, unit = age_str.split()[:2]\n",
    "    num = int(num)\n",
    "    if 'day' in unit:\n",
    "        return num\n",
    "    elif 'week' in unit:\n",
    "        return num * 7\n",
    "    elif 'month' in unit:\n",
    "        return num * 30\n",
    "    elif 'year' in unit:\n",
    "        return num * 365\n",
    "    return np.nan\n",
    "\n",
    "test_df['Age upon Intake'] = test_df['Age upon Intake'].apply(convert_age_to_days)\n",
    "test_df['Age upon Intake'] = test_df['Age upon Intake'].fillna(test_df['Age upon Intake'].median())\n",
    "\n",
    "# print(test_df['Age upon Intake'].isnull().sum()) # => 0 missing vals\n",
    "\n",
    "# Breed:\n",
    "\n",
    "def process_breed(breed):\n",
    "    if pd.isnull(breed):\n",
    "        return pd.Series([\"Unknown\", True]) \n",
    "    \n",
    "    is_mix = \"Mix\" in breed or \"/\" in breed\n",
    "\n",
    "    if \"/\" in breed:\n",
    "        primary = breed.split(\"/\")[0].strip()\n",
    "    else:\n",
    "        primary = breed.replace(\" Mix\", \"\").strip()\n",
    "    return pd.Series([primary, is_mix])\n",
    "\n",
    "test_df[['Primary_Breed', 'Is_Mix']] = test_df['Breed'].apply(process_breed)\n",
    "\n",
    "test_df['Is_Mix'] = test_df['Is_Mix'].astype(int)\n",
    "\n",
    "vc = test_df['Primary_Breed'].value_counts()\n",
    "cumulative = vc.cumsum() / vc.sum()\n",
    "top_breeds = cumulative[cumulative <= 0.90].index\n",
    "test_df['Primary_Breed'] = test_df['Primary_Breed'].apply(lambda x: x if x in top_breeds else 'Other')\n",
    "\n",
    "# Drop the original 'Breed' column\n",
    "test_df = test_df.drop(columns=['Breed'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "base_colors = [\n",
    "    'White', 'Black', 'Brown', 'Tan', 'Blue', 'Orange', 'Red', 'Cream', 'Gray',\n",
    "    'Chocolate', 'Yellow', 'Fawn', 'Buff', 'Silver', 'Gold', 'Seal', 'Flame',\n",
    "    'Lilac', 'Apricot', 'Liver', 'Pink', 'Ruddy'\n",
    "]\n",
    "\n",
    "patterns = [\n",
    "    'Tabby', 'Brindle', 'Tricolor', 'Tortie', 'Calico', 'Point',\n",
    "    'Torbie', 'Merle', 'Sable', 'Lynx', 'Tick', 'Smoke', 'Tiger', 'Agouti'\n",
    "]\n",
    "\n",
    "color_groups = {\n",
    "    'Dark': ['Black', 'Chocolate', 'Seal'],\n",
    "    'Light': ['White', 'Cream', 'Buff', 'Silver'],\n",
    "    'Warm': ['Red', 'Orange', 'Flame', 'Gold', 'Apricot'],\n",
    "    'Cool': ['Blue', 'Gray', 'Lilac'],\n",
    "    'Neutral': ['Tan', 'Brown', 'Fawn', 'Yellow', 'Liver', 'Pink', 'Ruddy']\n",
    "}\n",
    "\n",
    "pattern_groups = {\n",
    "    'Striped': ['Tabby', 'Tiger', 'Lynx'],\n",
    "    'Blotched': ['Tortie', 'Calico', 'Torbie'],\n",
    "    'Gradient': ['Smoke', 'Point', 'Sable'],\n",
    "    'Mixed': ['Merle', 'Brindle', 'Tricolor'],\n",
    "    'Textured': ['Tick', 'Agouti'],\n",
    "    'None': []\n",
    "}\n",
    "\n",
    "\n",
    "color_to_group = {c: g for g, clist in color_groups.items() for c in clist}\n",
    "pattern_to_group = {p: g for g, plist in pattern_groups.items() for p in plist}\n",
    "\n",
    "# Group assignment functions\n",
    "def assign_color_group(color_str):\n",
    "    if pd.isnull(color_str): return \"Unknown\"\n",
    "    for part in re.split(r'[/ ]+', color_str):\n",
    "        name = part.strip().title()\n",
    "        if name in color_to_group:\n",
    "            return color_to_group[name]\n",
    "    return \"Other\"\n",
    "\n",
    "def assign_pattern_group(color_str):\n",
    "    if pd.isnull(color_str): return \"None\"\n",
    "    for part in re.split(r'[/ ]+', color_str):\n",
    "        name = part.strip().title()\n",
    "        if name in pattern_to_group:\n",
    "            return pattern_to_group[name]\n",
    "    return \"None\"\n",
    "\n",
    "# Apply to DataFrame\n",
    "test_df['Color_Group'] = test_df['Color'].apply(assign_color_group)\n",
    "test_df['Pattern_Group'] = test_df['Color'].apply(assign_pattern_group)\n",
    "\n",
    "# Drop the original 'Color' column\n",
    "test_df = test_df.drop(columns=['Color'], axis=1)\n",
    "\n",
    "oneHotEncodeList.append('Color_Group')\n",
    "oneHotEncodeList.append('Pattern_Group')\n",
    "\n",
    "test_df = pd.get_dummies(test_df, columns=oneHotEncodeList, drop_first=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "test_df['Primary_Breed'] = le.fit_transform(test_df['Primary_Breed'])\n",
    "\n",
    "features = test_df\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "# Use PCA to reduce dimensionality\n",
    "print(f\"Original features shape: {features.shape}\")\n",
    "\n",
    "pca = PCA(n_components=0.95)  # Keep 95% of variance\n",
    "features = pca.fit_transform(features)\n",
    "print(f\"Reduced features shape: {features.shape}\")\n",
    "\n",
    "\n",
    "predictions = best_rf.predict(features)\n",
    "\n",
    "# print(\"Predictions on test data:\")\n",
    "# print(predictions)\n",
    "# print(\"Predictions shape:\", predictions.shape)\n",
    "print(\"Length of predictions:\", len(predictions))\n",
    "\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "submission_df = pd.DataFrame({'Id': test_data['Id'], 'Outcome Type': predictions})\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file saved as submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
