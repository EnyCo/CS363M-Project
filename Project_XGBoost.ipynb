{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97832174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Raghav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d807f0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# Drop the unnecessary columns: 'Id', 'Name', 'Found Location', 'Outcome Time', 'Date of Birth'\n",
    "df = df.drop(columns=['Id', 'Name', 'Found Location', 'Outcome Time', 'Date of Birth'], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "816e836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_shelter_data(df, is_train=True, label_encoder=None):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    import numpy as np\n",
    "    import re\n",
    "    oneHotEncodeList = []\n",
    "\n",
    "    # Time features\n",
    "    df['hour'] = pd.to_datetime(df['Intake Time']).dt.hour\n",
    "    df['dayofweek'] = pd.to_datetime(df['Intake Time']).dt.dayofweek\n",
    "    df['month'] = pd.to_datetime(df['Intake Time']).dt.month\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
    "    df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * (df['month'] - 1) / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * (df['month'] - 1) / 12)\n",
    "    df = df.drop(columns=['Intake Time', 'hour', 'dayofweek', 'month'], axis=1)\n",
    "\n",
    "    # Intake Type\n",
    "    df = df[df['Intake Type'] != 'Wildlife']\n",
    "    oneHotEncodeList.append('Intake Type')\n",
    "\n",
    "    # Intake Condition\n",
    "    def group_intake_condition(condition):\n",
    "        if pd.isnull(condition): return 'Other'\n",
    "        condition = condition.lower()\n",
    "        if condition in ['med attn', 'medical', 'med urgent', 'neurologic', 'congenital', 'parvo', 'agonal']:\n",
    "            return 'Medical-related'\n",
    "        elif condition in ['neonatal', 'aged', 'pregnant', 'nursing']:\n",
    "            return 'Life stage'\n",
    "        elif condition in ['normal', 'injured', 'sick']:\n",
    "            return 'Health Status'\n",
    "        elif condition in ['behavior', 'feral']:\n",
    "            return 'Behavioral'\n",
    "        else:\n",
    "            return 'Other'\n",
    "    df['Intake Condition'] = df['Intake Condition'].apply(group_intake_condition)\n",
    "    oneHotEncodeList.append('Intake Condition')\n",
    "\n",
    "    # Animal Type\n",
    "    oneHotEncodeList.append('Animal Type')\n",
    "\n",
    "    # Sex and Fix Status\n",
    "    df['Sex upon Intake'] = df['Sex upon Intake'].fillna('Unknown')\n",
    "    def extract_sex_and_status(sex):\n",
    "        sex = str(sex).strip().lower()\n",
    "        if \"neutered\" in sex:\n",
    "            status = \"Neutered\"\n",
    "        elif \"spayed\" in sex:\n",
    "            status = \"Spayed\"\n",
    "        elif \"intact\" in sex:\n",
    "            status = \"Intact\"\n",
    "        else:\n",
    "            status = \"Unknown\"\n",
    "        if \"male\" in sex:\n",
    "            gender = \"Male\"\n",
    "        elif \"female\" in sex:\n",
    "            gender = \"Female\"\n",
    "        else:\n",
    "            gender = \"Unknown\"\n",
    "        return pd.Series([gender, status])\n",
    "    df[['Sex', 'Fixed_Status']] = df['Sex upon Intake'].apply(extract_sex_and_status)\n",
    "    df = df.drop('Sex upon Intake', axis=1)\n",
    "    oneHotEncodeList.extend(['Sex', 'Fixed_Status'])\n",
    "\n",
    "    # Age\n",
    "    def convert_age_to_days(age_str):\n",
    "        if pd.isnull(age_str): return np.nan\n",
    "        num, unit = age_str.split()[:2]\n",
    "        num = int(num)\n",
    "        if 'day' in unit: return num\n",
    "        elif 'week' in unit: return num * 7\n",
    "        elif 'month' in unit: return num * 30\n",
    "        elif 'year' in unit: return num * 365\n",
    "        return np.nan\n",
    "    df['Age upon Intake'] = df['Age upon Intake'].apply(convert_age_to_days)\n",
    "    df['Age upon Intake'] = df['Age upon Intake'].apply(lambda x: np.nan if x < 0 else x)\n",
    "    df['Age upon Intake'] = df['Age upon Intake'].fillna(df['Age upon Intake'].median())\n",
    "    df['Log_Age'] = np.log1p(df['Age upon Intake'])\n",
    "\n",
    "    # Breed\n",
    "    def process_breed(breed):\n",
    "        if pd.isnull(breed): return pd.Series([\"Unknown\", True])\n",
    "        is_mix = \"Mix\" in breed or \"/\" in breed\n",
    "        if \"/\" in breed:\n",
    "            primary = breed.split(\"/\")[0].strip()\n",
    "        else:\n",
    "            primary = breed.replace(\" Mix\", \"\").strip()\n",
    "        return pd.Series([primary, is_mix])\n",
    "    df[['Primary_Breed', 'Is_Mix']] = df['Breed'].apply(process_breed)\n",
    "    df['Is_Mix'] = df['Is_Mix'].astype(int)\n",
    "    df = df.drop(columns=['Breed'], axis=1)\n",
    "\n",
    "    # Top breed filtering (train only)\n",
    "    if is_train:\n",
    "        vc = df['Primary_Breed'].value_counts()\n",
    "        cumulative = vc.cumsum() / vc.sum()\n",
    "        global top_breeds\n",
    "        top_breeds = cumulative[cumulative <= 0.90].index.tolist()\n",
    "\n",
    "    # Apply top breed mapping\n",
    "    df['Primary_Breed'] = df['Primary_Breed'].apply(lambda x: x if x in top_breeds else 'Other')\n",
    "\n",
    "    # Label encode Primary_Breed\n",
    "    if is_train:\n",
    "        label_encoder = LabelEncoder()\n",
    "        # Inject 'Other' if not present, so it's always encoded\n",
    "        if 'Other' not in df['Primary_Breed'].values:\n",
    "            df.loc[df.index[0], 'Primary_Breed'] = 'Other'\n",
    "        \n",
    "        label_encoder.fit(df['Primary_Breed'])\n",
    "        df['Primary_Breed'] = label_encoder.transform(df['Primary_Breed'])\n",
    "\n",
    "\n",
    "    else:\n",
    "        df['Primary_Breed'] = df['Primary_Breed'].apply(lambda x: x if x in label_encoder.classes_ else 'Other')\n",
    "        if 'Other' not in label_encoder.classes_:\n",
    "            import numpy as np\n",
    "            label_encoder.classes_ = np.append(label_encoder.classes_, 'Other')\n",
    "        df['Primary_Breed'] = label_encoder.transform(df['Primary_Breed'])\n",
    "\n",
    "    # Color group and pattern group\n",
    "    color_groups = {\n",
    "        'Dark': ['Black', 'Chocolate', 'Seal'],\n",
    "        'Light': ['White', 'Cream', 'Buff', 'Silver'],\n",
    "        'Warm': ['Red', 'Orange', 'Flame', 'Gold', 'Apricot'],\n",
    "        'Cool': ['Blue', 'Gray', 'Lilac'],\n",
    "        'Neutral': ['Tan', 'Brown', 'Fawn', 'Yellow', 'Liver', 'Pink', 'Ruddy']\n",
    "    }\n",
    "    pattern_groups = {\n",
    "        'Striped': ['Tabby', 'Tiger', 'Lynx'],\n",
    "        'Blotched': ['Tortie', 'Calico', 'Torbie'],\n",
    "        'Gradient': ['Smoke', 'Point', 'Sable'],\n",
    "        'Mixed': ['Merle', 'Brindle', 'Tricolor'],\n",
    "        'Textured': ['Tick', 'Agouti'],\n",
    "        'None': []\n",
    "    }\n",
    "    color_to_group = {c: g for g, clist in color_groups.items() for c in clist}\n",
    "    pattern_to_group = {p: g for g, plist in pattern_groups.items() for p in plist}\n",
    "\n",
    "    def assign_color_group(color_str):\n",
    "        if pd.isnull(color_str): return \"Unknown\"\n",
    "        for part in re.split(r'[/ ]+', color_str):\n",
    "            name = part.strip().title()\n",
    "            if name in color_to_group:\n",
    "                return color_to_group[name]\n",
    "        return \"Other\"\n",
    "\n",
    "    def assign_pattern_group(color_str):\n",
    "        if pd.isnull(color_str): return \"None\"\n",
    "        for part in re.split(r'[/ ]+', color_str):\n",
    "            name = part.strip().title()\n",
    "            if name in pattern_to_group:\n",
    "                return pattern_to_group[name]\n",
    "        return \"None\"\n",
    "\n",
    "    df['Color_Group'] = df['Color'].apply(assign_color_group)\n",
    "    df['Pattern_Group'] = df['Color'].apply(assign_pattern_group)\n",
    "    df = df.drop(columns=['Color'], axis=1)\n",
    "    oneHotEncodeList.extend(['Color_Group', 'Pattern_Group'])\n",
    "\n",
    "    # One-hot encode\n",
    "    df = pd.get_dummies(df, columns=oneHotEncodeList, drop_first=True)\n",
    "\n",
    "    # Final return\n",
    "    if is_train:\n",
    "        features = df.drop(columns=['Outcome Type'])\n",
    "        labels = df['Outcome Type']\n",
    "        return features, labels, label_encoder\n",
    "    else:\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3cd308a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raghav\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [21:30:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best Parameters: {'xgb__learning_rate': 0.1, 'xgb__max_depth': 7, 'xgb__n_estimators': 200, 'xgb__subsample': 0.8}\n",
      "✅ Best CV Macro F1 Score: 0.40538156613913207\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, make_scorer, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "# Load your dataset preprocess_shelter_data(df, is_train=True, label_encoder=None)\n",
    "X, y, label_encoder = preprocess_shelter_data(df, is_train=True)\n",
    "\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Label encode the target variable\n",
    "if y.dtype == \"object\" or y.dtype.name == \"category\":\n",
    "    y = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "class_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "# {'Adoption': 0, 'Died': 1, 'Euthanasia': 2, 'Return to Owner': 3, 'Transfer': 4}\n",
    "\n",
    "smote_strategy = {\n",
    "    class_mapping['Died']: 1000,\n",
    "    class_mapping['Euthanasia']: 3000\n",
    "}\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"smote\", SMOTE(sampling_strategy='not majority', random_state=42)),\n",
    "    (\"xgb\", XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss'))\n",
    "])\n",
    "\n",
    "\n",
    "# Define parameter grid\n",
    "# param_grid = {\n",
    "#     \"adaboost__estimator__max_depth\": [1, 2, 3],\n",
    "#     \"adaboost__n_estimators\": [50, 100, 150],\n",
    "#     \"adaboost__learning_rate\": [0.5, 1.0]\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    \"xgb__n_estimators\": [100, 200],\n",
    "    \"xgb__max_depth\": [3, 5, 7],\n",
    "    \"xgb__learning_rate\": [0.01, 0.1],\n",
    "    \"xgb__subsample\": [0.8, 1]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring='f1_macro', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Best model evaluation\n",
    "print(\"✅ Best Parameters:\", grid_search.best_params_)\n",
    "print(\"✅ Best CV Macro F1 Score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b30b76aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.84      0.73     55044\n",
      "           1       0.57      0.18      0.27      1041\n",
      "           2       0.53      0.19      0.28      3449\n",
      "           3       0.61      0.59      0.60     16598\n",
      "           4       0.69      0.46      0.55     35024\n",
      "\n",
      "    accuracy                           0.65    111156\n",
      "   macro avg       0.61      0.45      0.49    111156\n",
      "weighted avg       0.66      0.65      0.64    111156\n",
      "\n",
      "[[46093    63   182  3687  5019]\n",
      " [  505   188    16    38   294]\n",
      " [ 1543     7   655   379   865]\n",
      " [ 5797     2   107  9774   918]\n",
      " [16656    70   277  2025 15996]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model on the training set\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X)\n",
    "print(\"✅ Training Set Classification Report:\")\n",
    "print(classification_report(y, y_pred))\n",
    "print(confusion_matrix(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ca0ec34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raghav\\AppData\\Local\\Temp\\ipykernel_20024\\3216828942.py:8: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['hour'] = pd.to_datetime(df['Intake Time']).dt.hour\n",
      "C:\\Users\\Raghav\\AppData\\Local\\Temp\\ipykernel_20024\\3216828942.py:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['dayofweek'] = pd.to_datetime(df['Intake Time']).dt.dayofweek\n",
      "C:\\Users\\Raghav\\AppData\\Local\\Temp\\ipykernel_20024\\3216828942.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['month'] = pd.to_datetime(df['Intake Time']).dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test Set Predictions Saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Try the best model on the unlabeled test set\n",
    "data = pd.read_csv('test.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_test = preprocess_shelter_data(df_test, is_train=False, label_encoder=label_encoder)\n",
    "\n",
    "\n",
    "df_test = df_test.drop(columns=['Id', 'Date of Birth', 'Found Location'], axis=1)\n",
    "\n",
    "y_pred_test = best_model.predict(df_test)\n",
    "y_pred_test = label_encoder.inverse_transform(y_pred_test)\n",
    "df_test['Outcome Type'] = y_pred_test\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'Id': data['Id'],\n",
    "    'Outcome Type': y_pred_test\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"✅ Test Set Predictions Saved to submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
