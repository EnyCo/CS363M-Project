{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec87bcb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a0a2dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Raghav\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "25ca0a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# Drop the unnecessary columns: 'Id', 'Name', 'Found Location', 'Outcome Time', 'Date of Birth'\n",
    "df = df.drop(columns=['Id', 'Name', 'Found Location', 'Outcome Time', 'Date of Birth'], axis=1)\n",
    "\n",
    "oneHotEncodeList = []\n",
    "\n",
    "# Intake Time: \n",
    "\n",
    "# Check for missing values in the 'Intake Time' column\n",
    "# print(df['Intake Time'].isnull().sum()) => 0 missing vals\n",
    "\n",
    "# Convert 'Intake Time' to hour, day of the week, and month columns to be transformed\n",
    "df['hour'] = pd.to_datetime(df['Intake Time']).dt.hour\n",
    "df['dayofweek'] = pd.to_datetime(df['Intake Time']).dt.dayofweek\n",
    "df['month'] = pd.to_datetime(df['Intake Time']).dt.month\n",
    "\n",
    "\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "\n",
    "df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
    "df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
    "\n",
    "df['month_sin'] = np.sin(2 * np.pi * (df['month'] - 1) / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * (df['month'] - 1) / 12)\n",
    "\n",
    "# Drop the original 'Intake Time', 'hour', 'dayofweek', and 'month' columns\n",
    "df = df.drop(columns=['Intake Time', 'hour', 'dayofweek', 'month'], axis=1)\n",
    "\n",
    "# Intake Type: \n",
    "# Check for missing values in the 'Intake Type' column\n",
    "# print(df['Intake Type'].isnull().sum()) # => 0 missing vals\n",
    "\n",
    "# Delete the 'Wildlife' records (if any) from the 'Intake Type' column\n",
    "df = df[df['Intake Type'] != 'Wildlife']\n",
    "oneHotEncodeList.append('Intake Type')\n",
    "\n",
    "# Intake Condition:\n",
    "\n",
    "def group_intake_condition(condition):\n",
    "    if pd.isnull(condition):\n",
    "        return 'Other'\n",
    "    condition = condition.lower()\n",
    "    if condition in ['med attn', 'medical', 'med urgent', 'neurologic', 'congenital', 'parvo', 'agonal']:\n",
    "        return 'Medical-related'\n",
    "    elif condition in ['neonatal', 'aged', 'pregnant', 'nursing']:\n",
    "        return 'Life stage'\n",
    "    elif condition in ['normal', 'injured', 'sick']:\n",
    "        return 'Health Status'\n",
    "    elif condition in ['behavior', 'feral']:\n",
    "        return 'Behavioral'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "df['Intake Condition'] = df['Intake Condition'].apply(group_intake_condition)\n",
    "\n",
    "oneHotEncodeList.append('Intake Condition')\n",
    "\n",
    "# Animal Type:\n",
    "oneHotEncodeList.append('Animal Type')\n",
    "\n",
    "# Sex upon Intake: Split into two features => Sex and Neutered/Spayed\n",
    "\n",
    "# Check for missing values\n",
    "df['Sex upon Intake'] = df['Sex upon Intake'].fillna('Unknown')\n",
    "# print(df['Sex upon Intake'].isnull().sum())\n",
    "\n",
    "\n",
    "def extract_sex_and_status(sex):\n",
    "    if pd.isnull(sex): return pd.Series([\"Unknown\", \"Unknown\"])\n",
    "    \n",
    "    sex = sex.strip().lower()\n",
    "    if \"neutered\" in sex:\n",
    "        status = \"Neutered\"\n",
    "    elif \"spayed\" in sex:\n",
    "        status = \"Spayed\"\n",
    "    elif \"intact\" in sex:\n",
    "        status = \"Intact\"\n",
    "    else:\n",
    "        status = \"Unknown\"\n",
    "\n",
    "    if \"male\" in sex:\n",
    "        gender = \"Male\"\n",
    "    elif \"female\" in sex:\n",
    "        gender = \"Female\"\n",
    "    else:\n",
    "        gender = \"Unknown\"\n",
    "\n",
    "    return pd.Series([gender, status])\n",
    "\n",
    "df[['Sex', 'Fixed_Status']] = df['Sex upon Intake'].apply(extract_sex_and_status)\n",
    "\n",
    "\n",
    "oneHotEncodeList.append('Sex')\n",
    "oneHotEncodeList.append('Fixed_Status')\n",
    "\n",
    "# Drop original Sex upon Intake\n",
    "df = df.drop('Sex upon Intake', axis=1)\n",
    "\n",
    "\n",
    "# Age upon Intake: Convert to numeric values (in days) and drop the original column\n",
    "\n",
    "# print(df['Age upon Intake'].isnull().sum()) # => 0 missing vals\n",
    "def convert_age_to_days(age_str):\n",
    "    if pd.isnull(age_str):\n",
    "        return np.nan\n",
    "    num, unit = age_str.split()[:2]\n",
    "    num = int(num)\n",
    "    if 'day' in unit:\n",
    "        return num\n",
    "    elif 'week' in unit:\n",
    "        return num * 7\n",
    "    elif 'month' in unit:\n",
    "        return num * 30\n",
    "    elif 'year' in unit:\n",
    "        return num * 365\n",
    "    return np.nan\n",
    "\n",
    "df['Age upon Intake'] = df['Age upon Intake'].apply(convert_age_to_days)\n",
    "df['Age upon Intake'] = df['Age upon Intake'].fillna(df['Age upon Intake'].median())\n",
    "\n",
    "# print(df['Age upon Intake'].isnull().sum()) # => 0 missing vals\n",
    "\n",
    "# Breed:\n",
    "\n",
    "def process_breed(breed):\n",
    "    if pd.isnull(breed):\n",
    "        return pd.Series([\"Unknown\", True]) \n",
    "    \n",
    "    is_mix = \"Mix\" in breed or \"/\" in breed\n",
    "\n",
    "    if \"/\" in breed:\n",
    "        primary = breed.split(\"/\")[0].strip()\n",
    "    else:\n",
    "        primary = breed.replace(\" Mix\", \"\").strip()\n",
    "    return pd.Series([primary, is_mix])\n",
    "\n",
    "df[['Primary_Breed', 'Is_Mix']] = df['Breed'].apply(process_breed)\n",
    "\n",
    "df['Is_Mix'] = df['Is_Mix'].astype(int)\n",
    "\n",
    "vc = df['Primary_Breed'].value_counts()\n",
    "cumulative = vc.cumsum() / vc.sum()\n",
    "top_breeds = cumulative[cumulative <= 0.90].index\n",
    "df['Primary_Breed'] = df['Primary_Breed'].apply(lambda x: x if x in top_breeds else 'Other')\n",
    "\n",
    "# Drop the original 'Breed' column\n",
    "df = df.drop(columns=['Breed'], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1cdedbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "\n",
    "# Color: We have 3 potential features to extract from the color column\n",
    "# Base Colors (e.g., black, white, brown)\n",
    "# Patterns (e.g., tabby, brindle, tortie, merle)\n",
    "# Number of colors (solid vs. multi-colored)\n",
    "\n",
    "\n",
    "# color_counter = Counter()\n",
    "# pattern_counter = Counter()\n",
    "# for val in df['Color'].dropna():\n",
    "#     parts = re.split(r'[/ ]+', val)  # splits on '/' and spaces\n",
    "#     for part in parts:\n",
    "#         part_clean = part.strip().title()\n",
    "#         if part_clean: \n",
    "#             color_counter[part_clean] += 1\n",
    "\n",
    "\n",
    "base_colors = [\n",
    "    'White', 'Black', 'Brown', 'Tan', 'Blue', 'Orange', 'Red', 'Cream', 'Gray',\n",
    "    'Chocolate', 'Yellow', 'Fawn', 'Buff', 'Silver', 'Gold', 'Seal', 'Flame',\n",
    "    'Lilac', 'Apricot', 'Liver', 'Pink', 'Ruddy'\n",
    "]\n",
    "\n",
    "patterns = [\n",
    "    'Tabby', 'Brindle', 'Tricolor', 'Tortie', 'Calico', 'Point',\n",
    "    'Torbie', 'Merle', 'Sable', 'Lynx', 'Tick', 'Smoke', 'Tiger', 'Agouti'\n",
    "]\n",
    "\n",
    "color_groups = {\n",
    "    'Dark': ['Black', 'Chocolate', 'Seal'],\n",
    "    'Light': ['White', 'Cream', 'Buff', 'Silver'],\n",
    "    'Warm': ['Red', 'Orange', 'Flame', 'Gold', 'Apricot'],\n",
    "    'Cool': ['Blue', 'Gray', 'Lilac'],\n",
    "    'Neutral': ['Tan', 'Brown', 'Fawn', 'Yellow', 'Liver', 'Pink', 'Ruddy']\n",
    "}\n",
    "\n",
    "pattern_groups = {\n",
    "    'Striped': ['Tabby', 'Tiger', 'Lynx'],\n",
    "    'Blotched': ['Tortie', 'Calico', 'Torbie'],\n",
    "    'Gradient': ['Smoke', 'Point', 'Sable'],\n",
    "    'Mixed': ['Merle', 'Brindle', 'Tricolor'],\n",
    "    'Textured': ['Tick', 'Agouti'],\n",
    "    'None': []\n",
    "}\n",
    "\n",
    "\n",
    "color_to_group = {c: g for g, clist in color_groups.items() for c in clist}\n",
    "pattern_to_group = {p: g for g, plist in pattern_groups.items() for p in plist}\n",
    "\n",
    "# Group assignment functions\n",
    "def assign_color_group(color_str):\n",
    "    if pd.isnull(color_str): return \"Unknown\"\n",
    "    for part in re.split(r'[/ ]+', color_str):\n",
    "        name = part.strip().title()\n",
    "        if name in color_to_group:\n",
    "            return color_to_group[name]\n",
    "    return \"Other\"\n",
    "\n",
    "def assign_pattern_group(color_str):\n",
    "    if pd.isnull(color_str): return \"None\"\n",
    "    for part in re.split(r'[/ ]+', color_str):\n",
    "        name = part.strip().title()\n",
    "        if name in pattern_to_group:\n",
    "            return pattern_to_group[name]\n",
    "    return \"None\"\n",
    "\n",
    "# Apply to DataFrame\n",
    "df['Color_Group'] = df['Color'].apply(assign_color_group)\n",
    "df['Pattern_Group'] = df['Color'].apply(assign_pattern_group)\n",
    "\n",
    "# Drop the original 'Color' column\n",
    "df = df.drop(columns=['Color'], axis=1)\n",
    "\n",
    "oneHotEncodeList.append('Color_Group')\n",
    "oneHotEncodeList.append('Pattern_Group')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1c794b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age upon Intake     Outcome Type      hour_sin      hour_cos  \\\n",
      "0           2920.0  Return to Owner  1.224647e-16 -1.000000e+00   \n",
      "1            330.0  Return to Owner -1.000000e+00 -1.836970e-16   \n",
      "2            730.0         Transfer  0.000000e+00  1.000000e+00   \n",
      "3            730.0  Return to Owner  1.224647e-16 -1.000000e+00   \n",
      "4           2190.0  Return to Owner  7.071068e-01 -7.071068e-01   \n",
      "\n",
      "   dayofweek_sin  dayofweek_cos     month_sin     month_cos  \\\n",
      "0      -0.781831       0.623490  1.224647e-16 -1.000000e+00   \n",
      "1       0.433884      -0.900969  1.000000e+00  6.123234e-17   \n",
      "2       0.433884      -0.900969  8.660254e-01 -5.000000e-01   \n",
      "3      -0.974928      -0.222521  5.000000e-01  8.660254e-01   \n",
      "4       0.781831       0.623490  1.000000e+00  6.123234e-17   \n",
      "\n",
      "        Primary_Breed  Is_Mix  ...  Color_Group_Dark  Color_Group_Light  \\\n",
      "0               Other       0  ...             False               True   \n",
      "1               Other       1  ...             False               True   \n",
      "2  Domestic Shorthair       0  ...             False              False   \n",
      "3  Labrador Retriever       1  ...              True              False   \n",
      "4               Other       1  ...              True              False   \n",
      "\n",
      "   Color_Group_Neutral  Color_Group_Other  Color_Group_Warm  \\\n",
      "0                False              False             False   \n",
      "1                False              False             False   \n",
      "2                False              False              True   \n",
      "3                False              False             False   \n",
      "4                False              False             False   \n",
      "\n",
      "   Pattern_Group_Gradient  Pattern_Group_Mixed  Pattern_Group_None  \\\n",
      "0                   False                False                True   \n",
      "1                    True                False               False   \n",
      "2                   False                False               False   \n",
      "3                   False                False                True   \n",
      "4                   False                False                True   \n",
      "\n",
      "   Pattern_Group_Striped  Pattern_Group_Textured  \n",
      "0                  False                   False  \n",
      "1                  False                   False  \n",
      "2                   True                   False  \n",
      "3                  False                   False  \n",
      "4                  False                   False  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 111156 entries, 0 to 111156\n",
      "Data columns (total 33 columns):\n",
      " #   Column                            Non-Null Count   Dtype  \n",
      "---  ------                            --------------   -----  \n",
      " 0   Age upon Intake                   111156 non-null  float64\n",
      " 1   Outcome Type                      111156 non-null  object \n",
      " 2   hour_sin                          111156 non-null  float64\n",
      " 3   hour_cos                          111156 non-null  float64\n",
      " 4   dayofweek_sin                     111156 non-null  float64\n",
      " 5   dayofweek_cos                     111156 non-null  float64\n",
      " 6   month_sin                         111156 non-null  float64\n",
      " 7   month_cos                         111156 non-null  float64\n",
      " 8   Primary_Breed                     111156 non-null  object \n",
      " 9   Is_Mix                            111156 non-null  int64  \n",
      " 10  Intake Type_Euthanasia Request    111156 non-null  bool   \n",
      " 11  Intake Type_Owner Surrender       111156 non-null  bool   \n",
      " 12  Intake Type_Public Assist         111156 non-null  bool   \n",
      " 13  Intake Type_Stray                 111156 non-null  bool   \n",
      " 14  Intake Condition_Health Status    111156 non-null  bool   \n",
      " 15  Intake Condition_Life stage       111156 non-null  bool   \n",
      " 16  Intake Condition_Medical-related  111156 non-null  bool   \n",
      " 17  Intake Condition_Other            111156 non-null  bool   \n",
      " 18  Animal Type_Dog                   111156 non-null  bool   \n",
      " 19  Sex_Unknown                       111156 non-null  bool   \n",
      " 20  Fixed_Status_Neutered             111156 non-null  bool   \n",
      " 21  Fixed_Status_Spayed               111156 non-null  bool   \n",
      " 22  Fixed_Status_Unknown              111156 non-null  bool   \n",
      " 23  Color_Group_Dark                  111156 non-null  bool   \n",
      " 24  Color_Group_Light                 111156 non-null  bool   \n",
      " 25  Color_Group_Neutral               111156 non-null  bool   \n",
      " 26  Color_Group_Other                 111156 non-null  bool   \n",
      " 27  Color_Group_Warm                  111156 non-null  bool   \n",
      " 28  Pattern_Group_Gradient            111156 non-null  bool   \n",
      " 29  Pattern_Group_Mixed               111156 non-null  bool   \n",
      " 30  Pattern_Group_None                111156 non-null  bool   \n",
      " 31  Pattern_Group_Striped             111156 non-null  bool   \n",
      " 32  Pattern_Group_Textured            111156 non-null  bool   \n",
      "dtypes: bool(23), float64(7), int64(1), object(2)\n",
      "memory usage: 11.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Review the DataFrame after processing\n",
    "# print(df.head())\n",
    "# print(df.info())\n",
    "\n",
    "# One-hot encoding for categorical variables\n",
    "# print(oneHotEncodeList)\n",
    "df = pd.get_dummies(df, columns=oneHotEncodeList, drop_first=True)\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8ded1200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = df.drop(columns=['Outcome Type']).values  # Drop the target column to get features\n",
    "y = df['Outcome Type'].astype('category').cat.codes.values  # Encode target labels as integers\n",
    "\n",
    "primary_breed_index = 0  # Index where PrimaryBreed is located in X\n",
    "primary_breed_column = X[:, primary_breed_index]\n",
    "\n",
    "# Encode string breed values to integers\n",
    "primary_breed_encoder = LabelEncoder()\n",
    "primary_breed_encoded = primary_breed_encoder.fit_transform(primary_breed_column)\n",
    "\n",
    "# Replace string column in X with dummy float (just to maintain shape)\n",
    "X[:, primary_breed_index] = 0.0  # We'll ignore this column during training\n",
    "\n",
    "# Number of unique breeds\n",
    "num_breeds = len(primary_breed_encoder.classes_)\n",
    "embedding_dim = 10  # You can tune this\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3fa3b6dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Other'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ensure all categorical columns are properly encoded\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m----> 3\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m primary_breed_encoded \u001b[38;5;241m=\u001b[39m primary_breed_encoded\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint64)\n\u001b[0;32m      6\u001b[0m X_train, X_val, y_train, y_val, pb_train, pb_val \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m      7\u001b[0m     X, y, primary_breed_encoded, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Other'"
     ]
    }
   ],
   "source": [
    "# Ensure all categorical columns are properly encoded\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = X.astype(np.float32)\n",
    "primary_breed_encoded = primary_breed_encoded.astype(np.int64)\n",
    "\n",
    "X_train, X_val, y_train, y_val, pb_train, pb_val = train_test_split(\n",
    "    X, y, primary_breed_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "pb_train_tensor = torch.tensor(pb_train, dtype=torch.long)\n",
    "pb_val_tensor = torch.tensor(pb_val, dtype=torch.long)\n",
    "\n",
    "# Create Datasets and DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, pb_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, pb_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "class MultiClassNN(nn.Module):\n",
    "    def __init__(self, num_breeds, embedding_dim, input_dim, num_classes):\n",
    "        super(MultiClassNN, self).__init__()\n",
    "        \n",
    "        # Embedding layer for PrimaryBreed\n",
    "        self.embedding = nn.Embedding(num_breeds, embedding_dim)\n",
    "        \n",
    "        # Fully connected layers for numeric features + embedded PrimaryBreed feature\n",
    "        self.fc1 = nn.Linear(input_dim + embedding_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc_out = nn.Linear(32, num_classes)  # Output layer for multi-class classification\n",
    "    \n",
    "    def forward(self, x_numeric, x_primary_breed):\n",
    "        # Apply embedding for PrimaryBreed\n",
    "        breed_embedded = self.embedding(x_primary_breed)\n",
    "        \n",
    "        # Concatenate numeric data and embedded PrimaryBreed data\n",
    "        x = torch.cat((x_numeric, breed_embedded), dim=1)\n",
    "        \n",
    "        # Pass through fully connected layers\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc_out(x)  # No activation here, as CrossEntropyLoss will apply softmax\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = MultiClassNN(\n",
    "    num_breeds=num_breeds,\n",
    "    embedding_dim=embedding_dim,\n",
    "    input_dim=len(numerical_features),\n",
    "    num_classes=5  # 5 possible outcome types\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs_numeric, inputs_primary_breed, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs_numeric, inputs_primary_breed)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    accuracy = correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs_numeric, inputs_primary_breed, targets in val_loader:\n",
    "            outputs = model(inputs_numeric, inputs_primary_breed)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "        \n",
    "        val_avg_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = correct / total\n",
    "        print(f'Validation Loss: {val_avg_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
